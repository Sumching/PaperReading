# NICE: NON-LINEAR INDEPENDENT COMPONENTS ESTIMATION

**作者丨苏剑林**

**单位丨广州火焰信息科技有限公司**

**研究方向丨NLP，神经网络**

**个人主页丨kexue.fm**



**前言：**自从在机器之心上看到了 Glow 模型之后（[下一个GAN？OpenAI提出可逆生成模型Glow](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3MzI4MjgzMw%3D%3D%26mid%3D2650745032%26idx%3D1%26sn%3Da889433dd4c4d9f62bfab347909d9d28%26chksm%3D871aecb6b06d65a02625abdf4b21a2116251e311a49508db587b76ae8f76d7a9e03d4a6ab80a%26scene%3D21%23wechat_redirect)），我就一直对其念念不忘。现在机器学习模型层出不穷，我也经常关注一些新模型动态，但很少像 Glow 模型那样让我怦然心动，有种“就是它了”的感觉。更意外的是，这个效果看起来如此好的模型，居然是我以前完全没有听说过的。于是我翻来覆去阅读了好几天，越读越觉得有意思，感觉通过它能将我之前的很多想法都关联起来。在此，先来个阶段总结。

## **背景**

本文主要是 ***NICE: Non-linear Independent Components Estimation\*** 一文的介绍和实现。这篇文章也是 [Glow 模型](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzIwMTc4ODE0Mw%3D%3D%26mid%3D2247490358%26idx%3D1%26sn%3Db4b5d6014bdd365456d500537ba5bcad%26chksm%3D96e9c4b6a19e4da08710a55935dc2e15b00838d5395fdf2a424c50dedff9af7fa11441741b9d%26scene%3D21%23wechat_redirect)的基础文章之一，可以说它就是 Glow 的奠基石。



■ 论文 | NICE: Non-linear Independent Components Estimation

■ 链接 | [https://www.paperweekly.site/papers/2206](https://link.zhihu.com/?target=https%3A//www.paperweekly.site/papers/2206)

■ 源码 | [https://github.com/laurent-dinh/nice](https://link.zhihu.com/?target=https%3A//github.com/laurent-dinh/nice)



**艰难的分布**

众所周知，目前主流的生成模型包括 VAE 和 GAN，但事实上除了这两个之外，还有基于 flow 的模型（flow 可以直接翻译为“流”，它的概念我们后面再介绍）。

事实上 flow 的历史和 VAE、GAN 它们一样悠久，但是 flow 却鲜为人知。在我看来，**大概原因是 flow 找不到像 GAN 一样的诸如“造假者-鉴别者”的直观解释吧，因为 flow 整体偏数学化，加上早期效果没有特别好但计算量又特别大，所以很难让人提起兴趣来**。不过现在看来，OpenAI 的这个好得让人惊叹的、基于 flow 的 Glow 模型，估计会让更多的人投入到 flow 模型的改进中。

![img](https://pic2.zhimg.com/80/v2-67ce7de77238c95eda5bbde4a075581d_hd.jpg)Glow模型生成的高清人脸

生成模型的本质，就是希望用一个我们知道的概率模型来拟合所给的数据样本，也就是说，我们得写出一个带参数 θ 的分布 qθ(x)。然而，我们的神经网络只是“万能函数拟合器”，却不是“万能分布拟合器”，也就是它原则上能拟合任意函数，但不能随意拟合一个概率分布，因为概率分布有“非负”和“归一化”的要求。这样一来，我们能直接写出来的只有离散型的分布，或者是连续型的高斯分布。

当然，从最严格的角度来看，图像应该是一个离散的分布，因为它是由有限个像素组成的，而每个像素的取值也是离散的、有限的，因此可以通过离散分布来描述。**这个思路的成果就是 PixelRNN 一类的模型了，我们称之为“自回归流”**，其特点就是无法并行，所以计算量特别大。所以，我们更希望用连续分布来描述图像。当然，图像只是一个场景，其他场景下我们也有很多连续型的数据，所以连续型的分布的研究是很有必要的。

**各显神通**

所以问题就来了，对于连续型的，我们也就只能写出高斯分布了，而且很多时候为了方便处理，我们只能写出各分量独立的高斯分布，这显然只是众多连续分布中极小的一部分，显然是不够用的。为了解决这个困境，我们通过积分来创造更多的分布：

![img](https://pic4.zhimg.com/80/v2-a875e28aa7c739f6dee5c32f60f2b5ab_hd.jpg)

这里 q(z) 一般是标准的高斯分布，而 qθ(x|z)=qθ(x|z) 可以选择任意的条件高斯分布或者狄拉克分布。这样的积分形式可以形成很多复杂的分布。理论上来讲，它能拟合任意分布。

现在分布形式有了，我们需要求出参数 θ，那一般就是最大似然，假设真实数据分布为 p̃(x)，那么我们就需要最大化目标：

![img](https://pic1.zhimg.com/80/v2-70f5871a4a0f0c69221c9b91cde8eabc_hd.jpg)

然而 qθ(x) 是积分形式的，能不能算下去很难说。

于是各路大神就“八仙过海，各显神通”了。其中，VAE 和 GAN 在不同方向上避开了这个困难。VAE 没有直接优化目标 (2)，而是优化一个更强的上界，这使得它只能是一个近似模型，无法达到良好的生成效果。GAN 则是通过一个交替训练的方法绕开了这个困难，确实保留了模型的精确性，所以它才能有如此好的生成效果。但不管怎么样，GAN 也不能说处处让人满意了，所以探索别的解决方法是有意义的。

**直面概率积分**

flow 模型选择了一条“硬路”：**直接把积分算出来。**

具体来说，flow 模型选择 q(x|z) 为狄拉克分布 δ(x−g(z))，而且 g(z) 必须是可逆的，也就是说：

![img](https://pic4.zhimg.com/80/v2-4aa9284ab58d20903b7c72bdc416b2cf_hd.jpg)

要从理论上（数学上）实现可逆，那么要求 z 和 x 的维度一样。假设 f,g 的形式都知道了，那么通过 (1) 算 q(x) 相当于是对 q(z) 做一个积分变换 z=f(x)。即本来是：

![img](https://pic1.zhimg.com/80/v2-7e6f63d25e08c5cad52659aef76b24c4_hd.jpg)

的标准高斯分布（D 是 z 的维度），现在要做一个变换 z=f(x)。注意概率密度函数的变量代换并不是简单地将 z 替换为 f(x) 就行了，还多出了一个**“雅可比行列式”的绝对值**，也就是：

![img](https://pic1.zhimg.com/80/v2-f2b70304667b30304f14412a3ea0a6b0_hd.jpg)

这样，对 f 我们就有两个要求：

\1. 可逆，并且易于求逆函数（它的逆 g 就是我们希望的生成模型）；

\2. 对应的雅可比行列式容易计算。

这样一来：

![img](https://pic1.zhimg.com/80/v2-8449fda149ed2a289189044c858a2e54_hd.jpg)

这个优化目标是可以求解的。并且由于 f 容易求逆，因此一旦训练完成，我们就可以随机采样一个 z，然后通过 f 的逆来生成一个样本 ![[公式]](https://www.zhihu.com/equation?tex=f%5E%7B-1%7D%28z%29%3Dg%28z%29) ，这就得到了生成模型。

## **flow**

前面我们已经介绍了 flow 模型的特点和难点，下面我们来详细展示 flow 模型是如何针对难点来解决问题的。因为本文主要是介绍第一篇文章 ***NICE: Non-linear Independent Components Estimation*** 的工作，因此本文的模型也专称为 NICE。

**分块耦合层**

相对而言，行列式的计算要比函数求逆要困难，所以我们从“要求 2”出发思考。熟悉线性代数的朋友会知道，三角阵的行列式最容易计算：**三角阵的行列式等于对角线元素之积**。所以我们应该要想办法使得变换f的雅可比矩阵为三角阵。NICE 的做法很精巧，它将 D 维的 x 分为两部分 x1,x2，然后取下述变换：

![img](https://pic2.zhimg.com/80/v2-d114d15188d03ab21d21c763ffb4c965_hd.jpg)

其中 x1,x2 是 x 的某种划分，m 是 x1 的任意函数。也就是说，将 x 分为两部分，然后按照上述公式进行变换，得到新的变量 h，这个我们称为“**加性耦合层**”（Additive Coupling）。不失一般性，可以将 x 各个维度进行重排，使得 x1=x1:d 为前 d 个元素，x2=xd+1:D 为 d+1∼D 个元素。

不难看出，这个变换的雅可比矩阵 ![[公式]](https://www.zhihu.com/equation?tex=%5Cleft%5B+%5Cfrac%7B%E2%88%82h%7D%7B%E2%88%82x%7D+%5Cright%5D) 是一个三角阵，而且对角线全部为 1，用分块矩阵表示为：

![img](https://pic3.zhimg.com/80/v2-38ef817fcad957a1830b0e70393cb0ba_hd.jpg)

这样一来，这个变换的雅可比行列式为 1，其对数为 0，这样就解决了行列式的计算问题。

同时，(7) 式的变换也是可逆的，其逆变换为：

![img](https://pic1.zhimg.com/80/v2-4398e81753777d3c7d0295e3d30c3a44_hd.jpg)

**细水长flow**

上面的变换让人十分惊喜：**可逆，而且逆变换也很简单，并没有增加额外的计算量**。尽管如此，我们可以留意到，变换 (7) 的第一部分是平凡的（恒等变换），因此单个变换不能达到非常强的非线性，所以我们需要多个简单变换的复合，以达到强非线性，增强拟合能力。

![img](https://pic1.zhimg.com/80/v2-4aaeb9400f6db116440dd26beae42b28_hd.jpg)

其中每个变换都是加性耦合层。这就好比流水一般，积少成多，细水长流，所以这样的一个流程成为一个“流（flow）”。也就是说，一个 flow 是多个加性耦合层的耦合。

由链式法则：

![img](https://pic1.zhimg.com/80/v2-a810e2b7971b5496d53477e0c06f162c_hd.jpg)

因为“矩阵的乘积的行列式等于矩阵的行列式的乘积”,而每一层都是加性耦合层，因此每一层的行列式为 1，所以结果就是：

![img](https://pic1.zhimg.com/80/v2-cd1b5d7e994f72ff9334452933f09620_hd.jpg)

考虑到下面的错位，行列式可能变为 -1，但绝对值依然为 1，所以我们依然不用考虑行列式。

**交错中前进**

要注意，如果耦合的顺序一直保持不变，即：

![img](https://pic2.zhimg.com/80/v2-afcf904641481f2684244734ed6a31b5_hd.jpg)

那么最后还是 z1=x1，第一部分依然是平凡的，如下图：

![img](https://pic4.zhimg.com/80/v2-70f916f8bfebc3baf8eebc31f232e68f_hd.jpg)简单的耦合使得其中一部分仍然保持恒等，信息没有充分混合

为了得到不平凡的变换，我们可以考虑在每次进行加性耦合前，打乱或反转输入的各个维度的顺序，或者简单地直接交换这两部分的位置，使得信息可以充分混合，比如：

![img](https://pic2.zhimg.com/80/v2-57e6a5c955a63f66d048a3ca7d738de9_hd.jpg)

如下图：

![img](https://pic4.zhimg.com/80/v2-afebf29c8d1107e8448ca4264a999023_hd.jpg)通过交叉耦合，充分混合信息，达到更强的非线性

**尺度变换层**

在文章的前半部分我们已经指出过，flow 是基于可逆变换的，所以当模型训练完成之后，我们同时得到了一个生成模型和一个编码模型。但也正是因为可逆变换，随机变量 z 和输入样本 x 具有同一大小。

当我们指定 z 为高斯分布时，它是遍布整个 D 维空间的，D 也就是输入 x 的尺寸。但虽然 x 具有 D 维，但它未必就真正能遍布整个 D 维空间，比如 MNIST 图像虽然有 784 个像素，但有些像素不管在训练集还是测试集，都一直保持为 0，这说明它远远没有 784 维那么大。

也就是说，**flow 这种基于可逆变换的模型，天生就存在比较严重的维度浪费问题**：输入数据明明都不是 D 维流形，但却要编码为一个 D 维流形，这可行吗？

为了解决这个情况，NICE 引入了一个尺度变换层，它对最后编码出来的每个维度的特征都做了个尺度变换，也就是 ![[公式]](https://www.zhihu.com/equation?tex=z%3Ds%5Cotimes+h%5E%7B%28n%29%7D) 这样的形式，其中 s=(s1,s2,…,sD) 也是一个要优化的参数向量（各个元素非负）。这个 s 向量能识别该维度的重要程度（越小越重要，越大说明这个维度越不重要，接近可以忽略），起到压缩流形的作用。

注意这个尺度变换层的雅可比行列式就不再是 1 了，可以算得它的雅可比矩阵为对角阵：

![img](https://pic3.zhimg.com/80/v2-10bbb99024aff81edc5445ca2c8d3e4e_hd.jpg)

所以它的行列式为 ![[公式]](https://www.zhihu.com/equation?tex=%5CPi_is_%7Bi%7D) 。于是根据 (6) 式，我们有对数似然：

![img](https://pic4.zhimg.com/80/v2-b1c99e37549e3ff58bfe4add525feab7_hd.jpg)

为什么这个尺度变换能识别特征的重要程度呢？其实这个尺度变换层可以换一种更加清晰的方式描述：我们开始设 z 的先验分布为标准正态分布，也就是各个方差都为 1。

事实上，我们可以将先验分布的方差也作为训练参数，这样训练完成后方差有大有小，方差越小，说明该特征的“弥散”越小，如果方差为 0，那么该特征就恒为均值 0，该维度的分布坍缩为一个点，于是这意味着流形减少了一维。

不同于 (4) 式，我们写出带方差的正态分布：

![img](https://pic3.zhimg.com/80/v2-b33891c2c6da4e561aa50d81bfc1d7d6_hd.jpg)

将流模型 z=f(x) 代入上式，然后取对数，类似 (6) 式，我们得到：

![img](https://pic4.zhimg.com/80/v2-bac8d4174e26a626473e80b3e49b117b_hd.jpg)

对比 (15) 式，其实就有 si=1/σi。**所以尺度变换层等价于将先验分布的方差（标准差）也作为训练参数，如果方差足够小，我们就可以认为该维度所表示的流形坍缩为一个点，从而总体流形的维度减 1，暗含了降维的可能。**

**特征解耦**

当我们将先验分布选为各分量独立的高斯分布时，除了采样上的方便，还能带来什么好处呢？

在 flow 模型中， ![[公式]](https://www.zhihu.com/equation?tex=f%5E%7B-1%7D) 是生成模型，可以用来随机生成样本，那么 f 就是编码器。但是不同于普通神经网络中的自编码器“强迫低维重建高维来提取有效信息”的做法，flow 模型是完全可逆的，那么就不存在信息损失的问题，那么这个编码器还有什么价值呢？

这就涉及到了“什么是好的特征”的问题了。在现实生活中，我们经常抽象出一些维度来描述事物，比如“高矮”、“肥瘦”、“美丑”、“贫富”等，这些维度的特点是：“当我们说一个人高时，他不是必然会肥或会瘦，也不是必然会有钱或没钱”，也就是说这些特征之间没有多少必然联系，不然这些特征就有冗余了。**所以，一个好的特征，理想情况下各个维度之间应该是相互独立的，这样实现了特征的解耦，使得每个维度都有自己独立的含义。**

这样，我们就能理解“先验分布为各分量独立的高斯分布”的好处了，由于各分量的独立性，我们有理由说当我们用f对原始特征进行编码时，输出的编码特征 z=f(x) 的各个维度是解耦的。

NICE 的全称 Non-linear Independent Components Estimation，翻译为“非线性独立成分估计”，就是这个含义。反过来，由于 z 的每个维度的独立性，理论上我们控制改变单个维度时，就可以看出生成图像是如何随着该维度的改变而改变，从而发现该维度的含义。

类似地，我们也可以对两幅图像的编码进行插值（加权平均），得到过渡自然的生成样本，这些在后面发展起来的 Glow 模型中体现得很充分。不过，我们后面只做了 MNIST 实验，所以本文中就没有特别体现这一点。

## **实验**

这里我们用 Keras 重现 NICE 一文中的 MNIST 实验。

**模型细节**

先来把 NICE 模型的各个部分汇总一下。NICE 模型是 flow 模型的一种，由多个加性耦合层组成，每个加性耦合层如 (7)，它的逆是 (9)。在耦合之前，需要反转输入的维度，使得信息充分混合。最后一层需要加个尺度变换层，最后的 loss 是 (15) 式的相反数。

加性耦合层需要将输入分为两部分，NICE 采用交错分区，即下标为偶数的作为第一部分，下标为奇数的作为第二部分，而每个 m(x) 则简单地用多层全连接（5 个隐藏层，每个层 1000 节点，relu 激活）。在 NICE 中一共耦合了 4 个加性耦合层。

**参考代码**

这里是我用 Keras 实现的参考代码：

[https://github.com/bojone/flow/blob/master/nice.py](https://link.zhihu.com/?target=https%3A//github.com/bojone/flow/blob/master/nice.py)

在我的实验中，20 个 epoch 内可以跑到最优，11s 一个 epoch（GTX1070 环境），最终的 loss 约为 -2200。

相比于原论文的实现，这里做了一些改动。对于加性耦合层，我用了 (9) 式作为前向，(7) 式作为其逆向。因为 m(x) 用 relu 激活，我们知道 relu 是非负的，因此两种选择是有点差别的。因为正向是编码器，而逆向是生成器，选用 (7) 式作为逆向，那么生成模型更倾向于生成正数，这跟我们要生成的图像是吻合的，因为我们需要生成的是像素值为 0～1 的图像。

![img](https://pic2.zhimg.com/80/v2-791289766576ed1d2af9f64b40f2c091_hd.jpg)NICE模型生成的数字样本

**退火参数**

虽然我们最终希望从标准正态分布中采样随机数来生成样本，但实际上对于训练好的模型，理想的采样方差并不一定是 1，而是在 1 上下波动，一般比 1 稍小。最终采样的正态分布的标准差，我们称之为退火参数。比如上面的参考实现中，我们的退火参数选为 0.8，目测在这时候生成模型的质量最优。

## **总结**

NICE 的模型还是比较庞大的，按照上述模型，模型的参数量约为 ![[公式]](https://www.zhihu.com/equation?tex=4%5Ctimes5%5Ctimes+1000%5E%7B2%7D%3D2%5Ctimes+10%5E%7B7%7D)，也就是两千万的参数只为训练一个 MNIST 生成模型，也是夸张。

NICE 整体还是比较简单粗暴的，首先加性耦合本身比较简单，其次模型 m 部分只是简单地用到了庞大的全连接层，还没有结合卷积等玩法，因此探索空间还有很大，Real NVP 和 Glow 就是它们的两个改进版本，它们的故事我们后面再谈。